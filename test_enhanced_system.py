#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆå¤šæ™ºèƒ½ä½“ç³»ç»Ÿæµ‹è¯•æ–‡ä»¶
æµ‹è¯•æ€»åˆ†æ€»æ¶æ„çš„æ•°æ®æµé€šå’ŒåŠŸèƒ½æ­£ç¡®æ€§
"""

import asyncio
import time
import logging
import json
from datetime import datetime
from typing import Dict, List, Any

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# æ·»åŠ è¿›åº¦æ¡æ”¯æŒ
try:
    from tqdm.asyncio import tqdm
except ImportError:
    # å¦‚æœæ²¡æœ‰å®‰è£…tqdmï¼Œä½¿ç”¨ç®€å•çš„æ›¿ä»£å“
    class tqdm:
        def __init__(self, *args, **kwargs):
            self.desc = kwargs.get('desc', '')
            print(f"å¼€å§‹: {self.desc}")
        
        def update(self, n=1):
            pass
        
        def close(self):
            print(f"å®Œæˆ: {self.desc}")
        
        def __enter__(self):
            return self
        
        def __exit__(self, *args):
            self.close()

# å¯¼å…¥ç³»ç»Ÿç»„ä»¶
from agents.enhanced_multi_agent_system import EnhancedMultiAgentSystem

class SystemTester:
    """ç³»ç»Ÿæµ‹è¯•å™¨"""
    
    def __init__(self):
        self.test_results = []
        self.config = {
            'dashscope_api_key': 'sk-8b654ec58c4c49f6a30cfb3d555a95d0',
            'consensus_threshold': 0.7,
            'max_agents': 6,
            'coordination_timeout': 30,
            'reasoning_depth': 3
        }
        
        # æµ‹è¯•ç”¨ä¾‹
        self.test_cases = [
            {
                "name": "æ­£é¢è¯„ä»·æµ‹è¯•",
                "content": "è¿™ä¸ªäº§å“è´¨é‡å¾ˆå¥½ï¼ŒæœåŠ¡æ€åº¦ä¹Ÿä¸é”™ï¼Œå¼ºçƒˆæ¨èç»™å¤§å®¶ï¼ç‰©æµå¾ˆå¿«ï¼ŒåŒ…è£…ä¹Ÿå¾ˆä»”ç»†ã€‚",
                "platform": "taobao",
                "expected_decision": "approved",
                "description": "æµ‹è¯•æ­£é¢å†…å®¹çš„å¤„ç†"
            },
            {
                "name": "è½»å¾®è´Ÿé¢æµ‹è¯•", 
                "content": "ä»·æ ¼æœ‰ç‚¹è´µï¼Œä¸è¿‡è´¨é‡ç¡®å®è¿˜å¯ä»¥ï¼Œè€ƒè™‘ä¸­ã€‚",
                "platform": "weibo",
                "expected_decision": "approved",
                "description": "æµ‹è¯•è½»å¾®è´Ÿé¢ä½†æ•´ä½“ä¸­æ€§çš„å†…å®¹"
            },
            {
                "name": "æ˜æ˜¾æ¯’æ€§å†…å®¹æµ‹è¯•",
                "content": "è¿™åƒåœ¾äº§å“ï¼Œå–å®¶æ€åº¦æ¶åŠ£ï¼Œå®Œå…¨å°±æ˜¯éª—é’±çš„å‚»é€¼ï¼",
                "platform": "douyin", 
                "expected_decision": "rejected",
                "description": "æµ‹è¯•æ˜æ˜¾çš„æ¯’æ€§å†…å®¹æ£€æµ‹"
            },
            {
                "name": "å¤æ‚æ­§ä¹‰å†…å®¹æµ‹è¯•",
                "content": "è¿™è®¾è®¡çœŸæ˜¯å¤ªæœ‰åˆ›æ„äº†ï¼Œè®©äººå°è±¡æ·±åˆ»ã€‚è™½ç„¶å¯èƒ½ä¸æ˜¯æ‰€æœ‰äººéƒ½èƒ½æ¥å—è¿™ç§é£æ ¼ã€‚",
                "platform": "zhihu",
                "expected_decision": "approved",
                "description": "æµ‹è¯•å¤æ‚çš„æ­§ä¹‰å†…å®¹å¤„ç†"
            },
            {
                "name": "çŸ­å†…å®¹æµ‹è¯•",
                "content": "ä¸é”™",
                "platform": "wechat",
                "expected_decision": "approved", 
                "description": "æµ‹è¯•æçŸ­å†…å®¹çš„å¤„ç†"
            },
            {
                "name": "é•¿å†…å®¹æµ‹è¯•",
                "content": "ä»Šå¤©å»äº†ä¸€å®¶æ–°å¼€çš„é¤å…ï¼Œç¯å¢ƒå¾ˆä¸é”™ï¼Œè£…ä¿®é£æ ¼å¾ˆæœ‰ç‰¹è‰²ï¼ŒæœåŠ¡å‘˜æ€åº¦ä¹Ÿå¾ˆå¥½ã€‚ç‚¹äº†å‡ ä¸ªæ‹›ç‰Œèœï¼Œå‘³é“ç¡®å®ä¸é”™ï¼Œç‰¹åˆ«æ˜¯ä»–ä»¬å®¶çš„ç‰¹è‰²æ±¤ï¼Œå¾ˆé²œç¾ã€‚ä»·æ ¼ç›¸å¯¹æ¥è¯´è¿˜ç®—åˆç†ï¼Œæ€§ä»·æ¯”ä¸é”™ã€‚å”¯ä¸€çš„ä¸è¶³å°±æ˜¯ç­‰èœæ—¶é—´æœ‰ç‚¹é•¿ï¼Œå¯èƒ½æ˜¯å› ä¸ºåˆšå¼€ä¸šæ¯”è¾ƒå¿™ã€‚æ€»çš„æ¥è¯´ï¼Œè¿™æ¬¡ç”¨é¤ä½“éªŒè¿˜æ˜¯å¾ˆæ»¡æ„çš„ï¼Œä¸‹æ¬¡è¿˜ä¼šå†æ¥å°è¯•å…¶ä»–èœå“ã€‚æ¨èç»™æœ‹å‹ä»¬ã€‚",
                "platform": "dianping",
                "expected_decision": "approved",
                "description": "æµ‹è¯•é•¿å†…å®¹çš„å¤„ç†èƒ½åŠ›"
            },
            {
                "name": "è¾¹ç•Œæƒ…å†µæµ‹è¯•",
                "content": "è¿™ä¸ª...æ€ä¹ˆè¯´å‘¢ï¼Œæœ‰ç‚¹å¤æ‚ï¼Œå¯èƒ½éœ€è¦æ›´å¤šæ—¶é—´è€ƒè™‘ã€‚",
                "platform": "unknown",
                "expected_decision": "needs_human_review",
                "description": "æµ‹è¯•è¾¹ç•Œæƒ…å†µå’Œä¸ç¡®å®šå†…å®¹"
            }
        ]
    
     async def run_all_tests(self):
         """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
         print("å¼€å§‹å¢å¼ºç‰ˆå¤šæ™ºèƒ½ä½“ç³»ç»Ÿæµ‹è¯•")
         print("=" * 60)
         
         # åˆå§‹åŒ–ç³»ç»Ÿ
         system = EnhancedMultiAgentSystem(self.config)
         
         test_functions = [
             ("ç³»ç»Ÿåˆå§‹åŒ–", self._test_system_initialization),
             ("åŸºç¡€åŠŸèƒ½", self._test_basic_functionality),
             ("æ•°æ®æµé€š", self._test_data_flow),
             ("æ™ºèƒ½ä½“åä½œ", self._test_agent_collaboration),
             ("ä»²è£åŠŸèƒ½", self._test_arbitration_functionality),
             ("æ€§èƒ½å’Œå¹¶å‘", self._test_performance_and_concurrency),
             ("é”™è¯¯å¤„ç†", self._test_error_handling),
             ("å…¨éƒ¨æµ‹è¯•ç”¨ä¾‹", self._test_all_cases)
         ]
         
         try:
             # ä½¿ç”¨è¿›åº¦æ¡æ˜¾ç¤ºæµ‹è¯•è¿›åº¦
             with tqdm(total=len(test_functions), desc="æµ‹è¯•è¿›åº¦") as pbar:
                 for test_name, test_func in test_functions:
                     pbar.set_description(f"æ‰§è¡Œæµ‹è¯•: {test_name}")
                     await test_func(system)
                     pbar.update(1)
                     
         finally:
             await system.shutdown()
         
         # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
         self._generate_test_report()
    
    async def _test_system_initialization(self, system: EnhancedMultiAgentSystem):
        """æµ‹è¯•ç³»ç»Ÿåˆå§‹åŒ–"""
        print("\næµ‹è¯•1: ç³»ç»Ÿåˆå§‹åŒ–")
        
        test_result = {
            "test_name": "ç³»ç»Ÿåˆå§‹åŒ–æµ‹è¯•",
            "start_time": time.time(),
            "success": False,
            "details": {}
        }
        
        try:
            # åˆå§‹åŒ–ç³»ç»Ÿ
            await system.initialize()
            
            # æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
            status = system.get_system_status()
            
            test_result["details"] = {
                "is_initialized": status["is_initialized"],
                "is_running": status["is_running"],
                "components_count": {
                    "router": 1,
                    "sub_agents": status["components"]["sub_agents"]["count"],
                    "arbitrator": 1
                },
                "communication_hub": status["components"]["communication_hub"]["active_agents"]
            }
            
            # éªŒè¯ç»“æœ
            assert status["is_initialized"], "ç³»ç»Ÿæœªæ­£ç¡®åˆå§‹åŒ–"
            assert status["is_running"], "ç³»ç»Ÿæœªæ­£ç¡®å¯åŠ¨"
            assert status["components"]["sub_agents"]["count"] == 6, "å­æ™ºèƒ½ä½“æ•°é‡ä¸æ­£ç¡®"
            
            test_result["success"] = True
            print("  ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
            print(f"  å­æ™ºèƒ½ä½“æ•°é‡: {status['components']['sub_agents']['count']}")
            print(f"  æ´»è·ƒæ™ºèƒ½ä½“: {status['components']['communication_hub']['active_agents']}")
            
        except Exception as e:
            test_result["error"] = str(e)
            print(f"  ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
        
        test_result["duration"] = time.time() - test_result["start_time"]
        self.test_results.append(test_result)
    
     async def _test_basic_functionality(self, system: EnhancedMultiAgentSystem):
         """æµ‹è¯•åŸºç¡€åŠŸèƒ½"""
         print("\næµ‹è¯•2: åŸºç¡€åŠŸèƒ½")
        
        test_result = {
            "test_name": "åŸºç¡€åŠŸèƒ½æµ‹è¯•",
            "start_time": time.time(),
            "success": False,
            "details": {}
        }
        
        try:
            # æµ‹è¯•ç®€å•å†…å®¹å¤„ç†
            test_content = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å†…å®¹ï¼Œç”¨äºéªŒè¯ç³»ç»ŸåŸºç¡€åŠŸèƒ½ã€‚"
            result = await system.process_content(test_content, "test_platform")
            
            test_result["details"] = {
                "session_id": result.get("session_id"),
                "final_decision": result.get("final_decision"),
                "final_confidence": result.get("final_confidence"),
                "processing_time": result.get("processing_time"),
                "agents_involved": result.get("system_metadata", {}).get("total_agents_involved", 0)
            }
            
            # éªŒè¯ç»“æœ
            assert "final_decision" in result, "ç¼ºå°‘æœ€ç»ˆå†³ç­–"
            assert "final_confidence" in result, "ç¼ºå°‘ç½®ä¿¡åº¦"
            assert result["final_decision"] in ["approved", "rejected", "needs_human_review"], "å†³ç­–ç»“æœæ— æ•ˆ"
            assert 0 <= result["final_confidence"] <= 1, "ç½®ä¿¡åº¦èŒƒå›´æ— æ•ˆ"
            
            test_result["success"] = True
            print("  åŸºç¡€å†…å®¹å¤„ç†æˆåŠŸ")
            print(f"  æœ€ç»ˆå†³ç­–: {result['final_decision']}")
            print(f"  ç½®ä¿¡åº¦: {result['final_confidence']:.3f}")
            print(f"  å¤„ç†æ—¶é—´: {result['processing_time']:.2f}ç§’")
            
        except Exception as e:
            test_result["error"] = str(e)
            print(f"  åŸºç¡€åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        
        test_result["duration"] = time.time() - test_result["start_time"]
        self.test_results.append(test_result)
    
    async def _test_data_flow(self, system: EnhancedMultiAgentSystem):
        """æµ‹è¯•æ•°æ®æµé€š"""
        print("\næµ‹è¯•3: æ•°æ®æµé€š")
        
        test_result = {
            "test_name": "æ•°æ®æµé€šæµ‹è¯•",
            "start_time": time.time(),
            "success": False,
            "details": {}
        }
        
        try:
            test_content = "æµ‹è¯•æ•°æ®åœ¨å„ä¸ªæ™ºèƒ½ä½“ä¹‹é—´çš„æµé€šæ˜¯å¦æ­£å¸¸ã€‚"
            result = await system.process_content(test_content, "flow_test")
            
            # æ£€æŸ¥æ•°æ®æµçš„å®Œæ•´æ€§
            routing_phase = result.get("routing_phase", {})
            sub_agents_phase = result.get("sub_agents_phase", {}) 
            arbitration_phase = result.get("arbitration_phase", {})
            
            test_result["details"] = {
                "routing_completed": bool(routing_phase.get("tasks_assigned", 0) > 0),
                "sub_agents_participated": len(sub_agents_phase.get("participating_agents", [])),
                "arbitration_completed": bool(arbitration_phase.get("arbitration_result")),
                "communication_events": result.get("system_metadata", {}).get("communication_events", 0),
                "data_flow_stages": {
                    "routing": bool(routing_phase),
                    "sub_agents": bool(sub_agents_phase), 
                    "arbitration": bool(arbitration_phase)
                }
            }
            
            # éªŒè¯æ•°æ®æµ
            assert routing_phase.get("tasks_assigned", 0) > 0, "è·¯ç”±é˜¶æ®µæœªåˆ†é…ä»»åŠ¡"
            assert len(sub_agents_phase.get("participating_agents", [])) > 0, "æ— å­æ™ºèƒ½ä½“å‚ä¸"
            assert arbitration_phase.get("arbitration_result"), "ä»²è£é˜¶æ®µæœªå®Œæˆ"
            
            test_result["success"] = True
            print("  è·¯ç”±é˜¶æ®µæ•°æ®ä¼ é€’æ­£å¸¸")
            print(f"  å­æ™ºèƒ½ä½“å‚ä¸æ•°: {len(sub_agents_phase.get('participating_agents', []))}")
            print("  ä»²è£é˜¶æ®µæ•°æ®æ¥æ”¶æ­£å¸¸")
            print(f"  é€šä¿¡äº‹ä»¶æ•°: {result.get('system_metadata', {}).get('communication_events', 0)}")
            
        except Exception as e:
            test_result["error"] = str(e)
            print(f"   æ•°æ®æµé€šæµ‹è¯•å¤±è´¥: {e}")
        
        test_result["duration"] = time.time() - test_result["start_time"]
        self.test_results.append(test_result)
    
    async def _test_agent_collaboration(self, system: EnhancedMultiAgentSystem):
        """æµ‹è¯•æ™ºèƒ½ä½“åä½œ"""
        print("\næµ‹è¯•4: æ™ºèƒ½ä½“åä½œ")
        
        test_result = {
            "test_name": "æ™ºèƒ½ä½“åä½œæµ‹è¯•",
            "start_time": time.time(),
            "success": False,
            "details": {}
        }
        
        try:
            # ä½¿ç”¨å¯èƒ½å¼•èµ·æ™ºèƒ½ä½“é—´åä½œçš„å¤æ‚å†…å®¹
            complex_content = "è¿™ä¸ªäº§å“çš„è´¨é‡è®©æˆ‘å¾ˆå›°æƒ‘ï¼Œè¯´ä¸ä¸Šå¥½è¿˜æ˜¯åï¼Œå¯èƒ½éœ€è¦æ›´å¤šæ—¶é—´è¯„ä¼°ã€‚"
            result = await system.process_content(complex_content, "collaboration_test")
            
            collaboration_results = result.get("sub_agents_phase", {}).get("collaboration_results", {})
            communication_log = result.get("arbitration_phase", {}).get("communication_log", {})
            
            test_result["details"] = {
                "collaboration_attempts": len(collaboration_results),
                "successful_collaborations": len([c for c in collaboration_results.values() if c.get("status") == "completed"]),
                "arbitrator_communications": len(communication_log),
                "collaboration_types": [c.get("type") for c in collaboration_results.values()],
                "agent_consensus": result.get("arbitration_phase", {}).get("arbitration_result", {}).get("agent_consensus_analysis", {})
            }
            
            # éªŒè¯åä½œåŠŸèƒ½
            # æ³¨æ„ï¼šåä½œå¯èƒ½ä¸æ€»æ˜¯å‘ç”Ÿï¼Œè¿™å–å†³äºå†…å®¹å’Œæ™ºèƒ½ä½“çŠ¶æ€
            print("  åä½œæœºåˆ¶è¿è¡Œæ­£å¸¸")
            print(f"  åä½œå°è¯•æ¬¡æ•°: {len(collaboration_results)}")
            print(f"  æˆåŠŸåä½œæ¬¡æ•°: {len([c for c in collaboration_results.values() if c.get('status') == 'completed'])}")
            print(f"  ä»²è£å™¨é€šä¿¡æ¬¡æ•°: {len(communication_log)}")
            
            test_result["success"] = True
            
        except Exception as e:
            test_result["error"] = str(e)
            print(f"  æ™ºèƒ½ä½“åä½œæµ‹è¯•å¤±è´¥: {e}")
        
        test_result["duration"] = time.time() - test_result["start_time"]
        self.test_results.append(test_result)
    
    async def _test_arbitration_functionality(self, system: EnhancedMultiAgentSystem):
        """æµ‹è¯•ä»²è£åŠŸèƒ½"""
        print("\næµ‹è¯•5: ä»²è£åŠŸèƒ½")
        
        test_result = {
            "test_name": "ä»²è£åŠŸèƒ½æµ‹è¯•",
            "start_time": time.time(),
            "success": False,
            "details": {}
        }
        
        try:
            # ä½¿ç”¨å¯èƒ½äº§ç”Ÿåˆ†æ­§çš„å†…å®¹
            controversial_content = "è¿™ä¸ªè¯„è®ºåŒ…å«ä¸€äº›äº‰è®®æ€§çš„è¡¨è¾¾ï¼Œå¯èƒ½éœ€è¦ä»”ç»†åˆ¤æ–­ã€‚"
            result = await system.process_content(controversial_content, "arbitration_test")
            
            arbitration_result = result.get("arbitration_phase", {}).get("arbitration_result", {})
            
            test_result["details"] = {
                "arbitration_completed": bool(arbitration_result),
                "final_decision": arbitration_result.get("final_decision"),
                "confidence_score": arbitration_result.get("confidence_score"),
                "has_reasoning": bool(arbitration_result.get("arbitration_reasoning")),
                "evidence_analysis": bool(arbitration_result.get("evidence_analysis")),
                "consensus_analysis": bool(arbitration_result.get("agent_consensus_analysis")),
                "risk_assessment": bool(arbitration_result.get("risk_assessment")),
                "recommendations": bool(arbitration_result.get("recommendations"))
            }
            
            # éªŒè¯ä»²è£åŠŸèƒ½
            assert arbitration_result, "ä»²è£ç»“æœä¸ºç©º"
            assert arbitration_result.get("final_decision") in ["approved", "rejected", "needs_human_review"], "ä»²è£å†³ç­–æ— æ•ˆ"
            assert "arbitration_reasoning" in arbitration_result, "ç¼ºå°‘ä»²è£æ¨ç†"
            assert "evidence_analysis" in arbitration_result, "ç¼ºå°‘è¯æ®åˆ†æ"
            
            test_result["success"] = True
            print("  ä»²è£å™¨æˆåŠŸç”Ÿæˆå†³ç­–")
            print(f"  æœ€ç»ˆå†³ç­–: {arbitration_result.get('final_decision')}")
            print(f"  ä»²è£ç½®ä¿¡åº¦: {arbitration_result.get('confidence_score', 0):.3f}")
            print("   ä»²è£æ¨ç†å®Œæ•´")
            print("  è¯æ®åˆ†æå®Œæ•´")
            
        except Exception as e:
            test_result["error"] = str(e)
            print(f"  ä»²è£åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        
        test_result["duration"] = time.time() - test_result["start_time"]
        self.test_results.append(test_result)
    
    async def _test_performance_and_concurrency(self, system: EnhancedMultiAgentSystem):
        """æµ‹è¯•æ€§èƒ½å’Œå¹¶å‘"""
        print("\næµ‹è¯•6: æ€§èƒ½å’Œå¹¶å‘")
        
        test_result = {
            "test_name": "æ€§èƒ½å’Œå¹¶å‘æµ‹è¯•",
            "start_time": time.time(),
            "success": False,
            "details": {}
        }
        
        try:
            # å¹¶å‘å¤„ç†å¤šä¸ªå†…å®¹
            test_contents = [
                "å¹¶å‘æµ‹è¯•å†…å®¹1ï¼šè¿™æ˜¯ä¸€ä¸ªæ­£é¢çš„è¯„ä»·ã€‚",
                "å¹¶å‘æµ‹è¯•å†…å®¹2ï¼šè¿™ä¸ªäº§å“è¿˜å¯ä»¥ã€‚", 
                "å¹¶å‘æµ‹è¯•å†…å®¹3ï¼šä¸å¤ªæ»¡æ„è¿™æ¬¡è´­ä¹°ã€‚"
            ]
            
            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = time.time()
            
            # åˆ›å»ºå¹¶å‘ä»»åŠ¡
            tasks = []
            for i, content in enumerate(test_contents):
                task = asyncio.create_task(
                    system.process_content(content, f"concurrent_test_{i}")
                )
                tasks.append(task)
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            total_time = time.time() - start_time
            
            # åˆ†æç»“æœ
            successful_results = [r for r in results if not isinstance(r, Exception)]
            failed_results = [r for r in results if isinstance(r, Exception)]
            
            avg_processing_time = sum(r.get("processing_time", 0) for r in successful_results) / len(successful_results) if successful_results else 0
            
            test_result["details"] = {
                "total_requests": len(test_contents),
                "successful_requests": len(successful_results),
                "failed_requests": len(failed_results),
                "total_time": total_time,
                "average_processing_time": avg_processing_time,
                "concurrency_efficiency": len(successful_results) / len(test_contents),
                "throughput": len(test_contents) / total_time
            }
            
            # éªŒè¯å¹¶å‘æ€§èƒ½
            assert len(successful_results) == len(test_contents), f"å¹¶å‘å¤„ç†å¤±è´¥ï¼ŒæˆåŠŸ{len(successful_results)}/{len(test_contents)}"
            assert total_time < avg_processing_time * len(test_contents), "å¹¶å‘æ•ˆç‡ä½äºé¢„æœŸ"
            
            test_result["success"] = True
            print(f"  å¹¶å‘å¤„ç† {len(test_contents)} ä¸ªè¯·æ±‚")
            print(f"  æ€»è€—æ—¶: {total_time:.2f}ç§’")
            print(f"  å¹³å‡å¤„ç†æ—¶é—´: {avg_processing_time:.2f}ç§’")
            print(f"  ååé‡: {len(test_contents)/total_time:.2f} è¯·æ±‚/ç§’")
            
        except Exception as e:
            test_result["error"] = str(e)
            print(f"  æ€§èƒ½å’Œå¹¶å‘æµ‹è¯•å¤±è´¥: {e}")
        
        test_result["duration"] = time.time() - test_result["start_time"]
        self.test_results.append(test_result)
    
    async def _test_error_handling(self, system: EnhancedMultiAgentSystem):
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        print("\næµ‹è¯•7: é”™è¯¯å¤„ç†")
        
        test_result = {
            "test_name": "é”™è¯¯å¤„ç†æµ‹è¯•",
            "start_time": time.time(),
            "success": False,
            "details": {}
        }
        
        try:
            # æµ‹è¯•å„ç§è¾¹ç•Œæƒ…å†µ
            edge_cases = [
                "",  # ç©ºå†…å®¹
                "a" * 10000,  # è¶…é•¿å†…å®¹
                "ç‰¹æ®Šå­—ç¬¦æµ‹è¯•: !@#$%^&*()_+{}[]|\\:;<>?",  # ç‰¹æ®Šå­—ç¬¦
                None,  # Noneå€¼ï¼ˆä½†æˆ‘ä»¬ä¼šè½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼‰
            ]
            
            error_handling_results = []
            
            for i, content in enumerate(edge_cases):
                try:
                    # å¤„ç†Noneå€¼
                    if content is None:
                        content = "None"
                    
                    result = await system.process_content(str(content), f"edge_case_{i}")
                    error_handling_results.append({
                        "case": f"edge_case_{i}",
                        "content_length": len(str(content)),
                        "success": True,
                        "decision": result.get("final_decision"),
                        "error": None
                    })
                    
                except Exception as e:
                    error_handling_results.append({
                        "case": f"edge_case_{i}",
                        "content_length": len(str(content)) if content else 0,
                        "success": False,
                        "decision": None,
                        "error": str(e)
                    })
            
            test_result["details"] = {
                "total_edge_cases": len(edge_cases),
                "handled_successfully": len([r for r in error_handling_results if r["success"]]),
                "error_cases": [r for r in error_handling_results if not r["success"]],
                "results": error_handling_results
            }
            
            # éªŒè¯é”™è¯¯å¤„ç†
            success_rate = len([r for r in error_handling_results if r["success"]]) / len(edge_cases)
            assert success_rate >= 0.5, f"é”™è¯¯å¤„ç†æˆåŠŸç‡è¿‡ä½: {success_rate}"
            
            test_result["success"] = True
            print(f"  è¾¹ç•Œæƒ…å†µå¤„ç†æˆåŠŸç‡: {success_rate:.1%}")
            print(f"  æˆåŠŸå¤„ç†: {len([r for r in error_handling_results if r['success']])}/{len(edge_cases)}")
            
            for result in error_handling_results:
                if result["success"]:
                    print(f"  {result['case']}: {result['decision']}")
                else:
                    print(f"   {result['case']}: {result['error']}")
            
        except Exception as e:
            test_result["error"] = str(e)
            print(f"    é”™è¯¯å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        
        test_result["duration"] = time.time() - test_result["start_time"]
        self.test_results.append(test_result)
    
    async def _test_all_cases(self, system: EnhancedMultiAgentSystem):
        """æµ‹è¯•æ‰€æœ‰é¢„å®šä¹‰æµ‹è¯•ç”¨ä¾‹"""
        print("\næµ‹è¯•8: å…¨éƒ¨æµ‹è¯•ç”¨ä¾‹")
        
        test_result = {
            "test_name": "å…¨éƒ¨æµ‹è¯•ç”¨ä¾‹",
            "start_time": time.time(),
            "success": False,
            "details": {}
        }
        
        try:
            case_results = []
            
            for case in self.test_cases:
                print(f"\n    æ‰§è¡Œ: {case['name']}")
                
                try:
                    result = await system.process_content(case["content"], case["platform"])
                    
                    actual_decision = result.get("final_decision")
                    expected_decision = case["expected_decision"]
                    confidence = result.get("final_confidence", 0)
                    processing_time = result.get("processing_time", 0)
                    
                    # åˆ¤æ–­æ˜¯å¦ç¬¦åˆé¢„æœŸï¼ˆå…è®¸ä¸€å®šçš„çµæ´»æ€§ï¼‰
                    decision_match = (actual_decision == expected_decision or 
                                    (expected_decision == "approved" and actual_decision in ["approved", "needs_human_review"]) or
                                    (expected_decision == "rejected" and actual_decision in ["rejected", "needs_human_review"]))
                    
                    case_result = {
                        "name": case["name"],
                        "expected": expected_decision,
                        "actual": actual_decision,
                        "confidence": confidence,
                        "processing_time": processing_time,
                        "match": decision_match,
                        "success": True
                    }
                    
                     if decision_match:
                         print(f"      å†³ç­–: {actual_decision} (é¢„æœŸ: {expected_decision}) æ­£ç¡®")
                     else:
                         print(f"       å†³ç­–: {actual_decision} (é¢„æœŸ: {expected_decision}) é”™è¯¯")
                    
                    print(f"      ç½®ä¿¡åº¦: {confidence:.3f}")
                    print(f"      è€—æ—¶: {processing_time:.2f}ç§’")
                    
                except Exception as e:
                    case_result = {
                        "name": case["name"],
                        "expected": case["expected_decision"],
                        "actual": "error",
                        "confidence": 0,
                        "processing_time": 0,
                        "match": False,
                        "success": False,
                        "error": str(e)
                    }
                    print(f"      é”™è¯¯: {e}")
                
                case_results.append(case_result)
            
            # è®¡ç®—æ€»ä½“æ€§èƒ½
            successful_cases = [r for r in case_results if r["success"]]
            matching_cases = [r for r in case_results if r.get("match", False)]
            
            test_result["details"] = {
                "total_cases": len(self.test_cases),
                "successful_cases": len(successful_cases),
                "matching_decisions": len(matching_cases),
                "success_rate": len(successful_cases) / len(self.test_cases),
                "accuracy_rate": len(matching_cases) / len(self.test_cases),
                "average_confidence": sum(r.get("confidence", 0) for r in successful_cases) / len(successful_cases) if successful_cases else 0,
                "average_processing_time": sum(r.get("processing_time", 0) for r in successful_cases) / len(successful_cases) if successful_cases else 0,
                "case_results": case_results
            }
            
            success_rate = len(successful_cases) / len(self.test_cases)
            accuracy_rate = len(matching_cases) / len(self.test_cases)
            
            assert success_rate >= 0.8, f"æˆåŠŸç‡è¿‡ä½: {success_rate}"
            
            test_result["success"] = True
            print(f"\n   æµ‹è¯•ç”¨ä¾‹æ€»ç»“:")
            print(f"   æˆåŠŸç‡: {success_rate:.1%} ({len(successful_cases)}/{len(self.test_cases)})")
            print(f"   å‡†ç¡®ç‡: {accuracy_rate:.1%} ({len(matching_cases)}/{len(self.test_cases)})")
            print(f"   å¹³å‡ç½®ä¿¡åº¦: {test_result['details']['average_confidence']:.3f}")
            print(f"   å¹³å‡å¤„ç†æ—¶é—´: {test_result['details']['average_processing_time']:.2f}ç§’")
            
        except Exception as e:
            test_result["error"] = str(e)
            print(f"   âŒ æµ‹è¯•ç”¨ä¾‹æ‰§è¡Œå¤±è´¥: {e}")
        
        test_result["duration"] = time.time() - test_result["start_time"]
        self.test_results.append(test_result)
    
    def _generate_test_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸ“‹ æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ")
        print("="*60)
        
        total_tests = len(self.test_results)
        successful_tests = len([r for r in self.test_results if r["success"]])
        total_duration = sum(r["duration"] for r in self.test_results)
        
        print(f"\nğŸ¯ æ€»ä½“ç»“æœ:")
        print(f"   æ€»æµ‹è¯•æ•°: {total_tests}")
        print(f"   æˆåŠŸæµ‹è¯•: {successful_tests}")
        print(f"   å¤±è´¥æµ‹è¯•: {total_tests - successful_tests}")
        print(f"   æˆåŠŸç‡: {successful_tests/total_tests:.1%}")
        print(f"   æ€»è€—æ—¶: {total_duration:.2f}ç§’")
        
        print(f"\nğŸ“ è¯¦ç»†ç»“æœ:")
        for result in self.test_results:
            status = "âœ…" if result["success"] else "âŒ"
            print(f"   {status} {result['test_name']}: {result['duration']:.2f}ç§’")
            if not result["success"] and "error" in result:
                print(f"      é”™è¯¯: {result['error']}")
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Šåˆ°æ–‡ä»¶
        report_data = {
            "test_summary": {
                "total_tests": total_tests,
                "successful_tests": successful_tests,
                "success_rate": successful_tests / total_tests,
                "total_duration": total_duration,
                "timestamp": datetime.utcnow().isoformat()
            },
            "test_results": self.test_results,
            "system_config": self.config
        }
        
        with open(f"test_report_{int(time.time())}.json", "w", encoding="utf-8") as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ è¯¦ç»†æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: test_report_{int(time.time())}.json")
        
        if successful_tests == total_tests:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¢å¼ºç‰ˆå¤šæ™ºèƒ½ä½“ç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼")
        else:
            print(f"\nâš ï¸ {total_tests - successful_tests} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®ã€‚")

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ›¡ï¸ SenTox å¢å¼ºç‰ˆå¤šæ™ºèƒ½ä½“å†…å®¹å®¡æ ¸ç³»ç»Ÿæµ‹è¯•")
    print("æ¶æ„: æ€»åˆ†æ€» (è·¯ç”±å™¨ â†’ å­æ™ºèƒ½ä½“ç¾¤ â†’ ä¸­å¿ƒä»²è£å™¨)")
    print("ç‰¹æ€§: æ€ç»´é“¾ã€åŠ¨ä½œé“¾ã€MCPåè®®ã€åŒå‘é€šä¿¡")
    
    tester = SystemTester()
    await tester.run_all_tests()

if __name__ == "__main__":
    asyncio.run(main())
